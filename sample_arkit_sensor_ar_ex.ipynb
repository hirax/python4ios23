{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARKit動作中のリアルタイム点群センシング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARFrameSemanticSmoothedSceneDepth is enabled.\n",
      "ARFrameSemanticSceneDepth is enabled.\n",
      "Captured.\n"
     ]
    }
   ],
   "source": [
    "import arkit.arkit_sensor_ar_ex as ar\n",
    "import copy\n",
    "from coreimage.core_image import *\n",
    "from uikit.ui_uiimage_convert import *\n",
    "\n",
    "# MyARViewクラスをインスタンス化して初期化する\n",
    "arview = ar.MyARView()\n",
    "arview.initScene()\n",
    "\n",
    "# ディスプレイ画面の大きさを調べて\n",
    "scr = ar.get_screen_size()\n",
    "# ディスプレイ画面の全面にAR表示を行う\n",
    "arview.initialize([0,0,scr.width,scr.height/2],\n",
    "                  False) # AR空間に座標軸や特徴点を表示するか\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# 色画像・距離画像を入れるリストを用意\n",
    "video_and_depths = []\n",
    "\n",
    "# AR処理中に呼び出されて、色画像・距離画像をリストに追加する関数\n",
    "def process(video_and_depth):    \n",
    "    video_and_depths.append(\n",
    "        {\n",
    "            \"video\": ui2np(ci2ui(pixelBuffer2ci(\n",
    "video_and_depth[\"video\"]))),\n",
    "            \"depth\":copy.copy(video_and_depth[\"depth\"])\n",
    "        }\n",
    "    )\n",
    "\n",
    "isNeedToBeCaptured = False # 色画像・距離画像取得を開始するか\n",
    "for i in range(5):\n",
    "    if isNeedToBeCaptured != False:\n",
    "        continue\n",
    "    # AR処理が外界を認識していたら、色画像・距離画像を取得する\n",
    "    if arview.arsession.currentFrame() is None:\n",
    "        pass\n",
    "    else: # MyARView の「色画像・距離画像」取得メソッドを呼ぶ\n",
    "        is_captured = arview.capture_video_and_depth(\n",
    "            process, # ユーザー処理関数\n",
    "            False)   # 複数フ`レームで「滑らか」にした距離マップ画像を使うか\n",
    "        if is_captured:\n",
    "            isNeedToBeCaptured = True\n",
    "            print(\"Captured.\")\n",
    "    time.sleep(0.5)\n",
    "            \n",
    "arview.close_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'video': array([[[251, 236, 209, 255],\n",
      "        [252, 237, 210, 255],\n",
      "        [251, 236, 209, 255],\n",
      "        ...,\n",
      "        [175, 178, 137, 255],\n",
      "        [172, 175, 135, 255],\n",
      "        [173, 176, 137, 255]],\n",
      "\n",
      "       [[251, 236, 209, 255],\n",
      "        [252, 237, 210, 255],\n",
      "        [252, 237, 210, 255],\n",
      "        ...,\n",
      "        [173, 176, 136, 255],\n",
      "        [171, 173, 133, 255],\n",
      "        [171, 173, 134, 255]],\n",
      "\n",
      "       [[251, 236, 209, 255],\n",
      "        [252, 237, 210, 255],\n",
      "        [250, 235, 208, 255],\n",
      "        ...,\n",
      "        [174, 177, 137, 255],\n",
      "        [171, 173, 134, 255],\n",
      "        [165, 167, 128, 255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 20,  26,  22, 255],\n",
      "        [ 18,  25,  21, 255],\n",
      "        [ 17,  23,  19, 255],\n",
      "        ...,\n",
      "        [205, 185, 152, 255],\n",
      "        [205, 185, 152, 255],\n",
      "        [206, 186, 153, 255]],\n",
      "\n",
      "       [[ 16,  22,  19, 255],\n",
      "        [ 14,  20,  18, 255],\n",
      "        [ 11,  18,  15, 255],\n",
      "        ...,\n",
      "        [208, 188, 155, 255],\n",
      "        [206, 186, 153, 255],\n",
      "        [205, 185, 152, 255]],\n",
      "\n",
      "       [[ 13,  19,  17, 255],\n",
      "        [ 14,  20,  18, 255],\n",
      "        [ 11,  17,  15, 255],\n",
      "        ...,\n",
      "        [207, 187, 154, 255],\n",
      "        [206, 186, 153, 255],\n",
      "        [206, 186, 153, 255]]], dtype=uint8), 'depth': array([[0.44970703, 0.43554688, 0.4008789 , ..., 0.04388428, 0.11022949,\n",
      "        0.09155273],\n",
      "       [0.45361328, 0.40307617, 0.37768555, ..., 0.05593872, 0.15075684,\n",
      "        0.09863281],\n",
      "       [0.35180664, 0.36938477, 0.3474121 , ..., 0.06118774, 0.09381104,\n",
      "        0.08288574],\n",
      "       ...,\n",
      "       [0.19360352, 0.19750977, 0.19873047, ..., 0.09069824, 0.10839844,\n",
      "        0.07647705],\n",
      "       [0.20300293, 0.19104004, 0.18615723, ..., 0.0916748 , 0.11065674,\n",
      "        0.08953857],\n",
      "       [0.19470215, 0.20617676, 0.20129395, ..., 0.09222412, 0.1315918 ,\n",
      "        0.11767578]], dtype=float32)}]\n"
     ]
    }
   ],
   "source": [
    "print( video_and_depths )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image: height:1440 pixels x width:1920 pixels\n",
      "depth: height:192 pixels x width:256 pixels\n"
     ]
    }
   ],
   "source": [
    "video_h, video_w, ch = video_and_depths[0]['video'].shape  # 取得した画像の縦・横サイズ\n",
    "print(\"image: height:{:d} pixels x width:{:d} pixels\".format(video_h, video_w))\n",
    "\n",
    "depth_h, depth_w = video_and_depths[0]['depth'].shape  # 取得した画像の縦・横サイズ\n",
    "print(\"depth: height:{:d} pixels x width:{:d} pixels\".format(depth_h, depth_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlibを使って画像を表示する\n",
    "from matplotlib import pylab as plt\n",
    "import cv2\n",
    "\n",
    "# 画像を表示する\n",
    "plt.figure(figsize=[10,10])\n",
    "\n",
    "plt.imshow(video_and_depths[0]['depth'], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlibを使って画像を表示する\n",
    "from matplotlib import pylab as plt\n",
    "import cv2\n",
    "\n",
    "plt.figure(figsize=[10,10])\n",
    "rgba_image =  video_and_depths[0]['video']\n",
    "plt.imshow(rgba_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
